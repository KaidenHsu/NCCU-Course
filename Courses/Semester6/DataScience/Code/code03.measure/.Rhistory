(y <- seq(1, 10, length.out = 5))
c(T,T,F,F) & c(T,F,T,F)
c(T,T,F,F) && c(T,F,T,F)
rep(1,10)
rep(10,1)
b<-c()
length(b)
is.null(b)
is.na(b)
?cor
c(6,'fred')
list(6,'fred')
b<-matrix(c(2,4,3,1,5,7), nrow=3,ncol=2)
b<-matrix(c(2,4,3,1,5,7), nrow=3,ncol=2)
b
(b<-matrix(c(2,4,3,1,5,7), nrow=3,ncol=2))
b
b[1,2]
b[2,1]
uciCar <- read.table(  	# Note: 1
'http://www.win-vector.com/dfiles/car.data.csv', 	# Note: 2
sep=',', 	# Note: 3
header=T 	# Note: 4
)
summary(uciCar)
str(uciCar)
324,000/5
324000/5
324000/5
10993%mod%1001
10993 %% 1001
3x143x5+4x91x4+8x77x12
3*143*5 + 4*91*4 + 8*77*12
3*143*54*91*4 + 8*77*12
3*143*54
3*143*5
4*91*4
8*77*12
5^720
2^3
?merge
authors <- data.frame(
surname = I(c("Tukey", "Venables", "Tierney", "Ripley", "McNeil")),
nationality = c("US", "Australia", "US", "UK", "Australia"),
deceased = c("yes", rep("no", 4)))
books <- data.frame(
name = I(c("Tukey", "Venables", "Tierney",
"Ripley", "Ripley", "McNeil", "R Core")),
title = c("Exploratory Data Analysis",
"Modern Applied Statistics ...",
"LISP-STAT",
"Spatial Statistics", "Stochastic Simulation",
"Interactive Data Analysis",
"An Introduction to R"),
other.author = c(NA, "Ripley", NA, NA, NA, NA,
"Venables & Smith"))
View(authors)
View(books)
(m1 <- merge(authors, books, by.x = "surname", by.y = "name"))
?boxplot
1500*1000
1500*1000/20
?boxplot
?hclust
round(3)
runif(3)
?runif
sample(1,3)
sample(1:3,3)
sample(1:3,3)
sample(1:3,3)
sample(1:3,3)
sample(1:3,3)
sample(1:3,3)
sample(1:3,3)
sample(1:3,3)
sample(1:3,3)
sample(1,2)
?sample
sample(x)
x <- 1:12
sample(x)
x <- c("1","2")
sample(x)
x <- c("1","2","3")
sample(x)
sample(x)
sample(x)
sample(x)
x <- c("littlefish0331","littlefish0331","littlefish0331","RyuChu","RyuChu","RickyLeeeee","Doppelfelix","spisdoor","y28235579","106753015","LauskiMori","liekee","hwanimi","TsaiZX","tqmisz12")
length(x)
x <- c("littlefish0331","lazurite","itsnotponpon","RyuChu","chensex","RickyLeeeee","Doppelfelix","spisdoor","y28235579","106753015","LauskiMori","liekee","hwanimi","TsaiZX","tqmisz12")
length(x)
180/length(x)
x <- c("littlefish0331","lazurite","itsnotponpon","RyuChu","chensex","RickyLeeeee","Doppelfelix","spisdoor","y28235579","106753015","LauskiMori","hwanimi","TsaiZX","tqmisz12")
x <- c("littlefish0331","lazurite","itsnotponpon","RyuChu","chensex","RickyLeeeee","Doppelfelix","spisdoor","y28235579","106753015","LauskiMori","hwanimi","TsaiZX")
x <- c("littlefish0331","lazurite","itsnotponpon","RyuChu","RickyLeeeee","Doppelfelix","spisdoor","y28235579","106753015","LauskiMori","hwanimi")
x <- c("littlefish0331","lazurite","itsnotponpon","RyuChu","RickyLeeeee","Doppelfelix","spisdoor","y28235579","106753015","LauskiMori")
length(x)
180/length(x)
sample(x)
sample(x)
sample(x)
sample(x)
sample(1:6)
sample(1:6)
sample(1:6)
x = matrix(c(3,0,0,4), nrow=2, ncol=2)
x
eigen(x)
P = matrix(c(0,-1,1,0), nrow=2, ncol=2)
P
P %*% x %*% t(P)
ker
spamD <- read.table('spamD.tsv',header=T,sep='\t')
spamTrain <- subset(spamD,spamD$rgroup>=10)
spamTest <- subset(spamD,spamD$rgroup<10)
setwd("~/Dropbox/13_NCCU/courses/DataScienceInPractice_資料科學實務/1061/codes/code03/")
spamD <- read.table('spamD.tsv',header=T,sep='\t')
spamTrain <- subset(spamD,spamD$rgroup>=10)
spamTest <- subset(spamD,spamD$rgroup<10)
spamVars <- setdiff(colnames(spamD),list('rgroup','spam'))
spamFormula <- as.formula(paste('spam=="spam"',
paste(spamVars,collapse=' + '),sep=' ~ '))
spamModel <- glm(spamFormula,family=binomial(link='logit'), data=spamTrain)
spamTrain$pred <- predict(spamModel,newdata=spamTrain, type='response')
spamTest$pred <- predict(spamModel,newdata=spamTest, type='response')
print(with(spamTrain,table(y=spam,glmPred=pred>0.5)))
print(with(spamTest,table(y=spam,glmPred=pred>0.5)))
sample <- spamTest[c(7,35,224,327),c('spam','pred')]
print(sample)
cM <- table(truth=spamTest$spam, prediction=spamTest$pred>0.5)
print(cM)
ggplot(data=spamTest) +
geom_density(aes(x=pred,color=spam,linetype=spam))
library(ggplot2)
ggplot(data=spamTest) +
geom_density(aes(x=pred,color=spam,linetype=spam))
library('ROCR')
eval <- prediction(spamTest$pred,spamTest$spam)
plot(performance(eval,"tpr","fpr"))
print(attributes(performance(eval,'auc'))$y.values[[1]])
likeli_model <- sum(ifelse(spamTest$spam=='spam', log(spamTest$pred), log(1-spamTest$pred)))
likeli_model/dim(spamTest)[[1]]
pNull <- sum(ifelse(spamTest$spam=='spam',1,0))/dim(spamTest)[[1]]
likeli_nullModel <- sum(ifelse(spamTest$spam=='spam',1,0))*log(pNull) + sum(ifelse(spamTest$spam=='spam',0,1))*log(1-pNull)
likeli_model
likeli_nullModel
log(0.9)
log(0.1)
set.seed(32297)
d <- data.frame(x=runif(100),y=runif(100))
clus <- kmeans(d,centers=5)
d$cluster <- clus$cluster
table(d$cluster)
library('ggplot2'); library('grDevices')
h <- do.call(rbind,
lapply(unique(clus$cluster),
function(c) { f <- subset(d,cluster==c); f[chull(f),]}))
ggplot() +
geom_text(data=d,aes(label=cluster,x=x,y=y,
color=cluster),size=3)  +
geom_polygon(data=h,aes(x=x,y=y,group=cluster,fill=as.factor(cluster)),
alpha=0.4,linetype=0) +
theme(legend.position = "none")
?chull
?stop
tst1 <- function(...) stop("dummy error")
try(tst1(1:10, long, calling, expression))
tst2 <- function(...) stop("dummy error", call. = FALSE)
try(tst2(1:10, longcalling, expression, but.not.seen.in.Error))
?dcast
library('reshape2')
?dcast
library('reshape2')
n <- dim(d)[[1]]
pairs <- data.frame(
ca = as.vector(outer(1:n,1:n,function(a,b) d[a,'cluster'])),
cb = as.vector(outer(1:n,1:n,function(a,b) d[b,'cluster'])),
dist = as.vector(outer(1:n,1:n,function(a,b)
sqrt((d[a,'x']-d[b,'x'])^2 + (d[a,'y']-d[b,'y'])^2)))
)
dcast(pairs,ca~cb,value.var='dist',mean)
library('rpart')
load('GCDData.RData')
# Step1: A decision tree model for finding bad loan applications (11th week)
model <- rpart(Good.Loan ~
Duration.in.month +
Installment.rate.in.percentage.of.disposable.income +
Credit.amount  +
Other.installment.plans,
data=d,
control=rpart.control(maxdepth=4),
method="class")
# Step2: plotting the confusion matrix
resultframe <- data.frame(Good.Loan=creditdata$Good.Loan,
pred=predict(model, type="class"))
(rtab <- table(resultframe))
library('rpart')
load('GCDData.RData')
# Step1: A decision tree model for finding bad loan applications (11th week)
model <- rpart(Good.Loan ~
Duration.in.month +
Installment.rate.in.percentage.of.disposable.income +
Credit.amount  +
Other.installment.plans,
data=d,
control=rpart.control(maxdepth=4),
method="class")
# Step2: plotting the confusion matrix
resultframe <- data.frame(Good.Loan=creditdata$Good.Loan,
pred=predict(model, type="class"))
(rtab <- table(resultframe))
library('rpart')
load('GCDData.RData')
# Step1: A decision tree model for finding bad loan applications (11th week)
model <- rpart(Good.Loan ~
Duration.in.month +
Installment.rate.in.percentage.of.disposable.income +
Credit.amount  +
Other.installment.plans,
data=d,
control=rpart.control(maxdepth=4),
method="class")
# Step2: plotting the confusion matrix
resultframe <- data.frame(Good.Loan=creditdata$Good.Loan,
pred=predict(model, type="class"))
(rtab <- table(resultframe))
load('GCDData.RData')
library('rpart')
load('GCDData.RData')
View(creditdata)
View(d)
View(resultframe)
library(ggplot2)
# load data
spamD <- read.table('spamD.tsv',header=T,sep='\t')
spamTrain <- subset(spamD,spamD$rgroup>=10)
spamTest <- subset(spamD,spamD$rgroup<10)
spamVars <- setdiff(colnames(spamD),list('rgroup','spam'))
# build model
spamFormula <- as.formula(paste('spam=="spam"',
paste(spamVars,collapse=' + '),sep=' ~ '))
spamModel <- glm(spamFormula,family=binomial(link='logit'), data=spamTrain)
# apply model
spamTrain$pred <- predict(spamModel,newdata=spamTrain, type='response')
spamTest$pred <- predict(spamModel,newdata=spamTest, type='response')
# print predicted result
print(with(spamTrain,table(y=spam,glmPred=pred>0.5)))
print(with(spamTest,table(y=spam,glmPred=pred>0.5)))
sample <- spamTest[c(7,35,224,327),c('spam','pred')]
print(sample)
cM <- table(truth=spamTest$spam, prediction=spamTest$pred>0.5)
print(cM)
# Making a double density plot
ggplot(data=spamTest) +
geom_density(aes(x=pred,color=spam,linetype=spam))
# AUC evaluation
library('ROCR')
library(ggplot2)
# load data
spamD <- read.table('spamD.tsv',header=T,sep='\t')
spamTrain <- subset(spamD,spamD$rgroup>=10)
spamTest <- subset(spamD,spamD$rgroup<10)
spamVars <- setdiff(colnames(spamD),list('rgroup','spam'))
# build model
spamFormula <- as.formula(paste('spam=="spam"',
paste(spamVars,collapse=' + '),sep=' ~ '))
spamModel <- glm(spamFormula,family=binomial(link='logit'), data=spamTrain)
# apply model
spamTrain$pred <- predict(spamModel,newdata=spamTrain, type='response')
spamTest$pred <- predict(spamModel,newdata=spamTest, type='response')
# print predicted result
print(with(spamTrain,table(y=spam,glmPred=pred>0.5)))
print(with(spamTest,table(y=spam,glmPred=pred>0.5)))
sample <- spamTest[c(7,35,224,327),c('spam','pred')]
print(sample)
cM <- table(truth=spamTest$spam, prediction=spamTest$pred>0.5)
print(cM)
# Making a double density plot
ggplot(data=spamTest) +
geom_density(aes(x=pred,color=spam,linetype=spam))
# AUC evaluation
library('ROCR')
eval <- prediction(spamTest$pred,spamTest$spam)
plot(performance(eval,"tpr","fpr"))
print(attributes(performance(eval,'auc'))$y.values[[1]])
# LOG LIKELIHOOD
likeli_model <- sum(ifelse(spamTest$spam=='spam', log(spamTest$pred), log(1-spamTest$pred)))
likeli_model/dim(spamTest)[[1]]
# Computing the null model’s log likelihood
pNull <- sum(ifelse(spamTest$spam=='spam',1,0))/dim(spamTest)[[1]]
likeli_nullModel <- sum(ifelse(spamTest$spam=='spam',1,0))*log(pNull) + sum(ifelse(spamTest$spam=='spam',0,1))*log(1-pNull)
# calcualte pseudo R-squared
S <- 0
1 - (-2*(likeli_model-S))/(-2*(likeli_nullModel-S))
#0.56
?summary()
library('rpart')
load('GCDData.RData')
# Step1: A decision tree model for finding bad loan applications (11th week)
model <- rpart(Good.Loan ~
Duration.in.month +
Installment.rate.in.percentage.of.disposable.income +
Credit.amount  +
Other.installment.plans,
data=d,
control=rpart.control(maxdepth=4),
method="class")
# Step2: plotting the confusion matrix
resultframe <- data.frame(Good.Loan=creditdata$Good.Loan,
pred=predict(model, type="class"))
(rtab <- table(resultframe))
View(creditdata)
View(resultframe)
library(ggplot2)
# load data
spamD <- read.table('spamD.tsv',header=T,sep='\t')
spamTrain <- subset(spamD,spamD$rgroup>=10)
spamTest <- subset(spamD,spamD$rgroup<10)
spamVars <- setdiff(colnames(spamD),list('rgroup','spam'))
# build model
spamFormula <- as.formula(paste('spam=="spam"',
paste(spamVars,collapse=' + '),sep=' ~ '))
spamModel <- glm(spamFormula,family=binomial(link='logit'), data=spamTrain)
# apply model
spamTrain$pred <- predict(spamModel,newdata=spamTrain, type='response')
spamTest$pred <- predict(spamModel,newdata=spamTest, type='response')
# print predicted result
print(with(spamTrain,table(y=spam,glmPred=pred>0.5)))
print(with(spamTest,table(y=spam,glmPred=pred>0.5)))
sample <- spamTest[c(7,35,224,327),c('spam','pred')]
print(sample)
cM <- table(truth=spamTest$spam, prediction=spamTest$pred>0.5)
print(cM)
# Making a double density plot
ggplot(data=spamTest) +
geom_density(aes(x=pred,color=spam,linetype=spam))
# AUC evaluation
library('ROCR')
eval <- prediction(spamTest$pred,spamTest$spam)
plot(performance(eval,"tpr","fpr"))
print(attributes(performance(eval,'auc'))$y.values[[1]])
# LOG LIKELIHOOD
likeli_model <- sum(ifelse(spamTest$spam=='spam', log(spamTest$pred), log(1-spamTest$pred)))
likeli_model/dim(spamTest)[[1]]
# Computing the null model’s log likelihood
pNull <- sum(ifelse(spamTest$spam=='spam',1,0))/dim(spamTest)[[1]]
likeli_nullModel <- sum(ifelse(spamTest$spam=='spam',1,0))*log(pNull) + sum(ifelse(spamTest$spam=='spam',0,1))*log(1-pNull)
# calculate pseudo R-squared
S <- 0
1 - (-2*(likeli_model-S))/(-2*(likeli_nullModel-S))
#0.56
View(spamD)
View(spamD)
spamVars
spamFormula
typeof(spamFormula)
class(spamFormula)
View(spamTrain)
?c()
ggplot(data=spamTest)
ggplot(data=spamTest) +
geom_density(aes(x=pred,color=spam,linetype=spam))
ggplot(data=spamTest) +
geom_density(aes(x=pred,color=spam))
ggplot(data=spamTest) +
geom_density(aes(x=pred))
ggplot(data=spamTest) +
geom_density(aes(x=pred,color=spam,linetype=spam))
plot(performance(eval,"tpr","fpr"))
attributes(cM)
attributes(performance(eval,'auc'))
typeof(attributes(performance(eval,'auc')))
performance(eval,'auc')
View(spamTest)
View(spamTest)
dim(spamTest)
pNull
# calculate pseudo R-squared
S <- 0
1 - (-2*(likeli_model-S))/(-2*(likeli_nullModel-S))
#0.56
t <- as.table(matrix(data=c(288-1,17,1,13882-17),nrow=2,ncol=2))
rownames(t) <- rownames(cM)
matrix(data=c(288-1,17,1,13882-17),nrow=2,ncol=2)
y_pred = [1, 1, 0]
y_pred = [1, 1, 0]
# Define predicted labels
y_pred = [1, 1, 0]
# Define predicted labels
y_pred = [1, 1, 0]
# Define predicted labels
y_pred <- [1, 1, 0]
# Define predicted labels
y_pred <- c(1, 1, 0)
# Define actual labels
y_true <- [1, 1, 1]
# Define predicted labels
y_pred <- c(1, 1, 0)
# Define actual labels
y_true <- c[1, 1, 1]
# Define predicted labels
y_pred <- c(1, 1, 0)
# Define actual labels
y_true <- c(1, 1, 1)
# Import the required function from sklearn
from sklearn.metrics import classification_report
d <- data.frame(y=(1:10)^2,x=1:10)
model <- lm(y~x,data=d)
d$prediction <- predict(model,newdata=d)
library('ggplot2')
ggplot(data=d) + geom_point(aes(x=x,y=y)) +
geom_line(aes(x=x,y=prediction),color='blue') +
geom_segment(aes(x=x,y=prediction,yend=y,xend=x)) + scale_y_continuous('')
#absolute error
sum(abs(d$prediction-d$y))
#mean absolute error
sum(abs(d$prediction-d$y))/length(d$y)
#relative absolute error
sum(abs(d$prediction-d$y))/sum(abs(d$y))
View(d)
library(ggplot2)
# load data
spamD <- read.table('spamD.tsv',header=T,sep='\t')
spamTrain <- subset(spamD,spamD$rgroup>=10)
spamTest <- subset(spamD,spamD$rgroup<10)
spamVars <- setdiff(colnames(spamD),list('rgroup','spam'))
# build model
spamFormula <- as.formula(paste('spam=="spam"',
paste(spamVars,collapse=' + '),sep=' ~ '))
spamModel <- glm(spamFormula,family=binomial(link='logit'), data=spamTrain)
# apply model
spamTrain$pred <- predict(spamModel,newdata=spamTrain, type='response')
spamTest$pred <- predict(spamModel,newdata=spamTest, type='response')
# print predicted result
print(with(spamTrain,table(y=spam,glmPred=pred>0.5)))
print(with(spamTest,table(y=spam,glmPred=pred>0.5)))
sample <- spamTest[c(7,35,224,327),c('spam','pred')]
print(sample)
cM <- table(truth=spamTest$spam, prediction=spamTest$pred>0.5)
print(cM)
# Making a double density plot
ggplot(data=spamTest) +
geom_density(aes(x=pred,color=spam,linetype=spam))
# AUC evaluation
library('ROCR')
eval <- prediction(spamTest$pred,spamTest$spam)
plot(performance(eval,"tpr","fpr"))
print(attributes(performance(eval,'auc'))$y.values[[1]])
# LOG LIKELIHOOD
likeli_model <- sum(ifelse(spamTest$spam=='spam', log(spamTest$pred), log(1-spamTest$pred)))
likeli_model/dim(spamTest)[[1]]
# Computing the null model’s log likelihood
# pNull is the proportion of emails that are spam
pNull <- sum(ifelse(spamTest$spam=='spam',1,0))/dim(spamTest)[[1]]
likeli_nullModel <- sum(ifelse(spamTest$spam=='spam',1,0))*log(pNull) + sum(ifelse(spamTest$spam=='spam',0,1))*log(1-pNull)
# calculate pseudo R-squared
S <- 0
1 - (-2*(likeli_model-S))/(-2*(likeli_nullModel-S))
#0.56
# The result (0.56) suggests that approximately 56% of the uncertainty
# in the dependent variable is explained by the predictors in the model,
# as compared to a model with no predictors.
View(spamTest)
install.packages(
"rsthemes",
repos = c(gadenbuie = 'https://gadenbuie.r-universe.dev', getOption("repos"))
)
rsthemes::install_rsthemes()
rsthemes::list_rsthemes()
#Clustering random data in the plane
set.seed(32297)
d <- data.frame(x=runif(100),y=runif(100))
clus <- kmeans(d,centers=5)
d$cluster <- clus$cluster
#Calculating the size of each cluster
table(d$cluster)
# plot cluster
library('ggplot2'); library('grDevices')
h <- do.call(rbind,
lapply(unique(clus$cluster),
function(c) { f <- subset(d,cluster==c); f[chull(f),]}))
ggplot() +
geom_text(data=d,aes(label=cluster,x=x,y=y,
color=cluster),size=3)  +
geom_polygon(data=h,aes(x=x,y=y,group=cluster,fill=as.factor(cluster)),
alpha=0.4,linetype=0) +
theme(legend.position = "none")
#Calculating the typical distance between items in every pair of clusters
library('reshape2')
n <- dim(d)[[1]]
pairs <- data.frame(
ca = as.vector(outer(1:n,1:n,function(a,b) d[a,'cluster'])),
cb = as.vector(outer(1:n,1:n,function(a,b) d[b,'cluster'])),
dist = as.vector(outer(1:n,1:n,function(a,b)
sqrt((d[a,'x']-d[b,'x'])^2 + (d[a,'y']-d[b,'y'])^2)))
)
dcast(pairs,ca~cb,value.var='dist',mean)
View(clus)
View(d)
?table
?table()
View(clus)
unique(clus$cluster)
clus[["cluster"]]
View(h)
View(pairs)
View(pairs)
dcast(pairs,ca~cb,value.var='dist',mean)
load("~/Desktop/Data Science/Codes/code03.measure/GCDData.RData")
View(clus)
